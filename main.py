import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, DistributedSampler
import random
from trainers.basetrain import BaseTrainer
from trainers.amptrain import AMPTrainer
from trainers.ddptrain import DDPTrainer
from trainers.fsdptrain import FSDPTrainer
from models.vae import G2E
from data import GFSReader, ERA5Reader, GFSERA5PairDataset, collate_fn
import os

def set_random_seed(seed, rank):
    random.seed(seed + rank)
    torch.manual_seed(seed + rank)
    torch.cuda.manual_seed_all(seed + rank)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"using device: {device}")

    # âœ… æ£€æŸ¥æ˜¯å¦åœ¨ DDP æ¨¡å¼
    is_distributed = "RANK" in os.environ and "WORLD_SIZE" in os.environ
    if is_distributed:
        rank = int(os.environ["RANK"])
        world_size = int(os.environ["WORLD_SIZE"])
    else:
        rank = 0
        world_size = 1

    # âœ… è®¾ç½®éšæœºç§å­
    set_random_seed(42, rank)

    gfs_reader_train = GFSReader(
        start_dt="2020-01-01 00:00:00",
        end_dt="2024-12-31 18:00:00"
    )
    era5_reader_train = ERA5Reader(
        start_dt="2020-01-01 00:00:00",
        end_dt="2024-12-31 18:00:00"
    )

    gfs_reader_test = GFSReader(
        start_dt="2020-01-01 00:00:00",
        end_dt="2024-12-31 18:00:00"
    )
    era5_reader_test = ERA5Reader(
        start_dt="2020-01-01 00:00:00",
        end_dt="2024-12-31 18:00:00"
    )

    train_vars = [
        "Temperature",
        "2 metre temperature",
        "10 metre U wind component",
        "100 metre U wind component",
        "10 metre V wind component",
        "100 metre V wind component",
        "U component of wind",
        "V component of wind",
        "Geopotential height",
        "2 metre dewpoint temperature"
    ]

    train_dataset = GFSERA5PairDataset(
        gfs_reader=gfs_reader_train,
        era5_reader=era5_reader_train,
        gfs_vars=train_vars,
        normalize=True,
        norm_cache_path="/cpfs01/projects-HDD/cfff-4a8d9af84f66_HDD/public/database/gfs_2020_2024_c10/era5_norm_1_8.npz",
        base_layers=13,
        pad_mode="repeat",
    )

    test_dataset = GFSERA5PairDataset(
        gfs_reader=gfs_reader_test,
        era5_reader=era5_reader_test,
        gfs_vars=train_vars,
        normalize=True,
        norm_cache_path="/cpfs01/projects-HDD/cfff-4a8d9af84f66_HDD/public/database/gfs_2020_2024_c10/era5_norm_1_8.npz",
        base_layers=13,
        pad_mode="repeat",
    )

    print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ")

    batch_size = 1
    
    # âœ… ä¸ºè®­ç»ƒé›†æ·»åŠ  DistributedSampler
    train_sampler = DistributedSampler(
        train_dataset,
        num_replicas=world_size,
        rank=rank,
        shuffle=True,
        seed=42
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        sampler=train_sampler,
        num_workers=2,
        collate_fn=lambda x: collate_fn(x, base_layers=13)
    )

    # âœ… ä¸ºæµ‹è¯•é›†æ·»åŠ  DistributedSampler
    test_sampler = DistributedSampler(
        test_dataset,
        num_replicas=world_size,
        rank=rank,
        shuffle=False,
        seed=42
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        sampler=test_sampler,
        num_workers=2,
        collate_fn=lambda x: collate_fn(x, base_layers=13)
    )
    
    if rank == 0:
        print(f"âœ… DataLoader åŠ è½½å®Œæ¯•")
        print(f"   è®­ç»ƒé›†æ ·æœ¬æ€»æ•°: {len(train_dataset)}")
        print(f"   æ¯å¼  GPU åˆ†é…: {len(train_dataset) // world_size}")

    #=========================================================================================================================================================
    #=========================================================================================================================================================
    
    model = G2E(
        in_ch=10, out_ch=10,
        widths=(32, 64, 128),
        encoder_cfg={
            "stage0": {"blocks": ["resblock"], "down": "conv"},
            "stage1": {"blocks": ["resblock"], "down": "conv"},
            "stage2": {"blocks": ["resblock"], "down": "conv"},
        },
        decoder_cfg={
            "stage0": {"blocks": ["resblock"], "up": "upsample"},
            "stage1": {"blocks": ["resblock"], "up": "upsample"},
        },
    )
    
    # âœ…âœ…âœ… åœ¨è¿™é‡Œæ·»åŠ æ¨¡å‹è¯Šæ–­ï¼ˆåˆ›å»º Trainer ä¹‹å‰ï¼‰
    if rank == 0:
        print("\n" + "="*80)
        print("ğŸ” æ¨¡å‹è¯Šæ–­ï¼šæ£€æŸ¥ VAE è¾“å‡º")
        print("="*80)
        
        # å°†æ¨¡å‹ä¸´æ—¶ç§»åˆ° device è¿›è¡Œæµ‹è¯•
        model_test = model.to(device)
        model_test.eval()
        
        with torch.no_grad():
            # åˆ›å»ºå°å°ºå¯¸çš„æµ‹è¯•è¾“å…¥ï¼ˆé¿å…æ˜¾å­˜çˆ†ç‚¸ï¼‰
            dummy_input = torch.randn(1, 10, 721, 1440).to(device)  # ä½¿ç”¨å°å°ºå¯¸
            
            try:
                x_recon, mu, log_var = model_test(dummy_input)
                
                print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
                print(f"   è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
                print(f"   è¾“å‡ºå½¢çŠ¶: {x_recon.shape}")
                print(f"   mu å½¢çŠ¶: {mu.shape}")
                print(f"   log_var å½¢çŠ¶: {log_var.shape}")
                print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                print(f"   mu èŒƒå›´: [{mu.min():.4f}, {mu.max():.4f}]")
                print(f"   mu å‡å€¼: {mu.mean():.4f}")
                print(f"   log_var èŒƒå›´: [{log_var.min():.4f}, {log_var.max():.4f}]")
                print(f"   log_var å‡å€¼: {log_var.mean():.4f}")
                
                # è®¡ç®— KL æ•£åº¦
                kl = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
                kl_per_element = kl / mu.numel()
                
                print(f"\nğŸ“ˆ KL æ•£åº¦:")
                print(f"   æ€» KL: {kl.item():.4f}")
                print(f"   å¹³å‡ KL (per element): {kl_per_element.item():.4f}")
                
                # è¯Šæ–­
                if kl.item() > 10000:
                    print(f"\nâš ï¸  è­¦å‘Šï¼šKL æ•£åº¦å¼‚å¸¸å¤§ ({kl.item():.2f})ï¼")
                    print(f"   å¯èƒ½åŸå› ï¼š")
                    print(f"   1. log_var åˆå§‹åŒ–è¿‡å¤§ (å½“å‰å‡å€¼: {log_var.mean():.4f})")
                    print(f"   2. mu åˆå§‹åŒ–è¿‡å¤§ (å½“å‰å‡å€¼: {mu.mean():.4f})")
                    print(f"   3. beta å¤ªå° (å½“å‰ beta: 1e-5)")
                    print(f"\n   å»ºè®®ï¼š")
                    print(f"   1. å¢å¤§ beta åˆ° 0.01 æˆ– 0.1")
                    print(f"   2. æ£€æŸ¥ VAE ä¸­ logvar å±‚çš„åˆå§‹åŒ–")
                elif kl.item() < 0.01:
                    print(f"\nâš ï¸  è­¦å‘Šï¼šKL æ•£åº¦è¿‡å° ({kl.item():.4f})ï¼Œå¯èƒ½åéªŒåç¼©ï¼")
                    print(f"   å»ºè®®ï¼šå‡å° beta æˆ–ä½¿ç”¨ KL annealing")
                else:
                    print(f"\nâœ… KL æ•£åº¦æ­£å¸¸")
                
                # æ£€æŸ¥é‡å»ºæŸå¤±
                recon = nn.functional.mse_loss(x_recon, dummy_input)
                print(f"\nğŸ“‰ é‡å»ºæŸå¤± (MSE): {recon.item():.4f}")
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰ NaN/Inf
                if torch.isnan(x_recon).any():
                    print(f"\nâŒ é”™è¯¯ï¼šè¾“å‡ºåŒ…å« NaNï¼")
                if torch.isinf(x_recon).any():
                    print(f"\nâŒ é”™è¯¯ï¼šè¾“å‡ºåŒ…å« Infï¼")
                    
            except Exception as e:
                print(f"\nâŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # å°†æ¨¡å‹ç§»å› CPUï¼ˆä¸ºäº† FSDP åŒ…è£…ï¼‰
        model = model_test.cpu()
        del model_test
        torch.cuda.empty_cache()
        
        print("="*80)
        print("ğŸ” æ¨¡å‹è¯Šæ–­å®Œæˆ\n")
    
    # âœ… ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨çš„é…ç½®
    optimizer_config = {
        'type': 'Adam',
        'lr': 1e-4,
        'weight_decay': 1e-5,
        'betas': (0.9, 0.999),
    }

    scheduler_config = {
        'type': 'CosineAnnealingLR',
        'T_max': 30,
        'eta_min': 1e-6,
    }

    trainer = FSDPTrainer(
        model=model,
        train_loader=train_loader,
        test_loader=test_loader,
        optimizer=None,
        scheduler=None,
        epochs=3,
        device=device,
        beta=1e-5,  # âœ… æ”¹ä¸º 0.01ï¼ˆä» 1e-5ï¼‰
        log_dir="./runs/experiment_fsdp",
        use_fsdp=True,
        save_dir="./checkpoints",
        save_interval=1,
        sharding_strategy="FULL_SHARD",
        mixed_precision=False,
        min_num_params=1e8,
        optimizer_config=optimizer_config,
        scheduler_config=scheduler_config,
    )
    
    if rank == 0:
        print("âœ… FSDPTrainer åˆå§‹åŒ–å®Œæˆ")
    
    trainer.train()


if __name__ == "__main__":
    main()
# export LD_PRELOAD=/home/ximutian/miniconda3/envs/xuyue/lib/libstdc++.so.6
# torchrun --nproc_per_node=2 main.py