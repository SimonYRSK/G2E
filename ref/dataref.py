import xarray as xr
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional

class GFSReader:
    def __init__(self, zarr_path: str, mapping: Dict = gfs2era5_mapping):
        self.zarr_path = zarr_path
        self.mapping = mapping  # ä¼ å…¥gfs2era5æ˜ å°„è¡¨
        self.ds = None  # å»¶è¿ŸåŠ è½½çš„Dataset
        self.time_index = None  # ç»Ÿä¸€æ—¶é—´ç´¢å¼•
        self.supported_gfs_vars = list(mapping.keys())  # æ”¯æŒçš„GFSå˜é‡å

    def _load_data(self):
        """å»¶è¿ŸåŠ è½½GFSæ•°æ®ï¼Œè§£ææ—¶é—´"""
        if self.ds is None:
            self.ds = xr.open_zarr(self.zarr_path, consolidated=True)
            self.time_index = pd.to_datetime(self.ds['time'].values).sort_values()
            print(f"âœ… GFSæ•°æ®åŠ è½½å®Œæˆ")
            print(f"   æ—¶é—´èŒƒå›´ï¼š{self.time_index.min()} ~ {self.time_index.max()}")
            print(f"   æ”¯æŒçš„å˜é‡ï¼š{self.supported_gfs_vars}")

    def read_by_time(self, target_time: pd.Timestamp, gfs_vars: Optional[List[str]] = None) -> Dict[str, np.ndarray]:
        """
        æŒ‰æ—¶é—´è¯»å–GFSå˜é‡ï¼Œè¿”å›{GFSé€šç”¨å˜é‡å: (å±‚æ•°, lat, lon)}
        Args:
            target_time: ç›®æ ‡æ—¶é—´ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
            gfs_vars: è¦è¯»å–çš„GFSå˜é‡ååˆ—è¡¨ï¼ˆé»˜è®¤è¯»å–æ‰€æœ‰æ”¯æŒçš„å˜é‡ï¼‰
        """
        self._load_data()
        gfs_vars = gfs_vars or self.supported_gfs_vars
        
        # 1. æ‰¾åˆ°GFSä¸­æœ€æ¥è¿‘çš„æ—¶é—´
        nearest_idx = np.argmin(np.abs(self.time_index - target_time))
        nearest_time = self.time_index[nearest_idx]

        # 2. è¯»å–æŒ‡å®šå˜é‡
        result = {}
        for gfs_var in gfs_vars:
            if gfs_var not in self.mapping:
                raise ValueError(f"GFSä¸æ”¯æŒå˜é‡{gfs_var}ï¼Œæ”¯æŒçš„å˜é‡ï¼š{self.supported_gfs_vars}")
            if gfs_var not in self.ds:
                raise ValueError(f"GFS Zarrä¸­æ²¡æœ‰å˜é‡{gfs_var}")
            
            # è¯»å–å˜é‡æ•°æ®
            var_data = self.ds[gfs_var].sel(time=nearest_time).values.squeeze()
            
            # å¤„ç†ç»´åº¦ï¼šsurfaceå˜é‡ï¼ˆæ— å±‚æ•°ï¼‰â†’ æ‰©å±•ä¸º(1, lat, lon)ï¼Œupper_airå˜é‡ä¿æŒ(13, lat, lon)
            var_type = self.mapping[gfs_var]["var_type"]
            if var_type == "surface" and var_data.ndim == 2:
                var_data = np.expand_dims(var_data, axis=0)  # (1, lat, lon)
            elif var_type == "upper_air" and var_data.ndim == 2:
                raise ValueError(f"GFSå˜é‡{gfs_var}æ˜¯é«˜ç©ºå˜é‡ï¼Œä½†æ•°æ®æ— å±‚æ•°ç»´åº¦ï¼")
            
            result[gfs_var] = var_data
            print(f"ğŸ“Œ GFSå˜é‡{gfs_var}å½¢çŠ¶ï¼š{var_data.shape}ï¼ˆ{self.mapping[gfs_var]['var_type']}ï¼‰")
        
        return result

    @property
    def all_gfs_vars(self) -> List[str]:
        """è¿”å›æ‰€æœ‰æ”¯æŒçš„GFSå˜é‡å"""
        return self.supported_gfs_vars


import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn import functional as F

class GFSERA5PairDataset(Dataset):
    def __init__(
        self,
        gfs_reader: GFSReader,
        era5_reader: ERA5Reader,
        gfs_vars: Optional[List[str]] = None,
        time_window: Tuple[str, str] = ("2020-01-01", "2020-01-31"),
        time_diff_threshold: int = 3600,  # æ—¶é—´å·®é˜ˆå€¼ï¼ˆç§’ï¼‰
        normalize: bool = True,
        spatial_shape: Tuple[int, int] = None  # ç»Ÿä¸€ç©ºé—´åˆ†è¾¨ç‡ï¼ˆlat, lonï¼‰
    ):
        self.gfs_reader = gfs_reader
        self.era5_reader = era5_reader
        self.gfs_vars = gfs_vars or gfs_reader.all_gfs_vars
        self.time_diff_threshold = time_diff_threshold
        self.normalize = normalize
        self.spatial_shape = spatial_shape  # ç»Ÿä¸€ç©ºé—´åˆ†è¾¨ç‡ï¼ˆå¯é€‰ï¼‰

        # 1. åŠ è½½æ—¶é—´ç´¢å¼•å¹¶ç­›é€‰æ—¶é—´çª—å£
        self.gfs_reader._load_data()
        self.era5_reader._load_data()
        start = pd.to_datetime(time_window[0])
        end = pd.to_datetime(time_window[1])
        self.gfs_times = gfs_reader.time_index[(gfs_reader.time_index >= start) & (gfs_reader.time_index <= end)]
        self.era5_times = era5_reader.time_index[(era5_reader.time_index >= start) & (era5_reader.time_index <= end)]

        # 2. ç”Ÿæˆæ—¶é—´é…å¯¹ï¼ˆæŒ‰æ—¶é—´å·®é˜ˆå€¼ï¼‰
        self.paired_times = self._generate_paired_times()
        if not self.paired_times:
            raise ValueError("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ—¶é—´å·®é˜ˆå€¼çš„é…å¯¹æ ·æœ¬")
        print(f"âœ… å…±æ‰¾åˆ°{len(self.paired_times)}ä¸ªæ—¶é—´é…å¯¹æ ·æœ¬")

        # 3. é¢„è®¡ç®—æ ‡å‡†åŒ–å‚æ•°ï¼ˆåŸºäºERA5ï¼‰
        self.norm_params = self._compute_norm_params() if normalize else None

        # 4. é¢„è®¡ç®—æ€»å±‚æ•°ï¼ˆæ‰€æœ‰å˜é‡çš„å±‚æ•°ä¹‹å’Œï¼Œç”¨äºbatchç»´åº¦æ‹¼æ¥ï¼‰
        self.total_layers = self._compute_total_layers()
        print(f"âœ… æ‰€æœ‰å˜é‡æ€»å±‚æ•°ï¼š{self.total_layers}")

    def _generate_paired_times(self) -> List[Tuple[pd.Timestamp, pd.Timestamp]]:
        """ç”Ÿæˆæ—¶é—´é…å¯¹ï¼ˆGFSæ—¶é—´, ERA5æ—¶é—´ï¼‰"""
        paired_times = []
        for gfs_time in self.gfs_times:
            time_diffs = np.abs((self.era5_times - gfs_time).total_seconds())
            min_diff = np.min(time_diffs)
            if min_diff <= self.time_diff_threshold:
                era5_time = self.era5_times[np.argmin(time_diffs)]
                paired_times.append((gfs_time, era5_time))
        return paired_times

    def _compute_total_layers(self) -> int:
        """è®¡ç®—æ‰€æœ‰å˜é‡çš„å±‚æ•°ä¹‹å’Œï¼ˆå¦‚ï¼šTemperature(13) + t2m(1) + ...ï¼‰"""
        total = 0
        for gfs_var in self.gfs_vars:
            # ä»æ˜ å°„è¡¨è·å–å±‚æ•°ï¼ˆERA5å˜é‡åˆ—è¡¨é•¿åº¦ = å±‚æ•°ï¼‰
            total += len(self.gfs_reader.mapping[gfs_var]["era5_vars"])
        return total

    def _compute_norm_params(self) -> Dict[str, Tuple[float, float]]:
        """æŒ‰GFSé€šç”¨å˜é‡è®¡ç®—æ ‡å‡†åŒ–å‚æ•°ï¼ˆå‡å€¼+æ ‡å‡†å·®ï¼‰"""
        norm_params = {}
        # å–å‰10ä¸ªæ ·æœ¬è®¡ç®—ç»Ÿè®¡é‡
        sample_times = self.paired_times[:10]
        for gfs_var in self.gfs_vars:
            all_data = []
            for _, era5_time in sample_times:
                data = self.era5_reader.read_by_time(era5_time, [gfs_var])[gfs_var]
                all_data.append(data)
            all_data = np.concatenate(all_data, axis=0)
            norm_params[gfs_var] = (np.mean(all_data), np.std(all_data))
        return norm_params

    def _normalize(self, data: np.ndarray, gfs_var: str) -> np.ndarray:
        """æ ‡å‡†åŒ–å•å˜é‡æ•°æ®"""
        mean, std = self.norm_params[gfs_var]
        return (data - mean) / (std + 1e-8)  # é¿å…é™¤0

    def _resize_spatial(self, tensor: torch.Tensor) -> torch.Tensor:
        """ç»Ÿä¸€ç©ºé—´åˆ†è¾¨ç‡ï¼ˆå¯é€‰ï¼‰"""
        if self.spatial_shape is None:
            return tensor
        # tensorå½¢çŠ¶ï¼š(å±‚æ•°, lat, lon) â†’ è½¬æˆ(1, å±‚æ•°, lat, lon)åšæ’å€¼ â†’ æ¢å¤(å±‚æ•°, lat, lon)
        tensor = tensor.unsqueeze(0)
        tensor = F.interpolate(tensor, size=self.spatial_shape, mode="bilinear", align_corners=False)
        return tensor.squeeze(0)

    def __len__(self) -> int:
        return len(self.paired_times)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        # 1. è·å–é…å¯¹æ—¶é—´
        gfs_time, era5_time = self.paired_times[idx]
        
        # 2. è¯»å–GFSå’ŒERA5æ•°æ®ï¼ˆ{GFSé€šç”¨å˜é‡: (å±‚æ•°, lat, lon)}ï¼‰
        gfs_data = self.gfs_reader.read_by_time(gfs_time, self.gfs_vars)
        era5_data = self.era5_reader.read_by_time(era5_time, self.gfs_vars)
        
        # 3. æ ‡å‡†åŒ– + ç©ºé—´åˆ†è¾¨ç‡ç»Ÿä¸€
        gfs_tensors = []
        era5_tensors = []
        for gfs_var in self.gfs_vars:
            # æ ‡å‡†åŒ–
            if self.normalize:
                gfs_var_data = self._normalize(gfs_data[gfs_var], gfs_var)
                era5_var_data = self._normalize(era5_data[gfs_var], gfs_var)
            else:
                gfs_var_data = gfs_data[gfs_var]
                era5_var_data = era5_data[gfs_var]
            
            # è½¬tensorå¹¶ç»Ÿä¸€ç©ºé—´åˆ†è¾¨ç‡
            gfs_tensor = torch.tensor(gfs_var_data, dtype=torch.float32)
            era5_tensor = torch.tensor(era5_var_data, dtype=torch.float32)
            gfs_tensor = self._resize_spatial(gfs_tensor)
            era5_tensor = self._resize_spatial(era5_tensor)
            
            # æ·»åŠ åˆ°åˆ—è¡¨ï¼ˆåç»­æ‹¼æ¥æ‰€æœ‰å˜é‡çš„å±‚æ•°ï¼‰
            gfs_tensors.append(gfs_tensor)
            era5_tensors.append(era5_tensor)
        
        # 4. æ‹¼æ¥æ‰€æœ‰å˜é‡çš„å±‚æ•° â†’ (æ€»å±‚æ•°, lat, lon)
        gfs_combined = torch.cat(gfs_tensors, axis=0)  # (æ€»å±‚æ•°, lat, lon)
        era5_combined = torch.cat(era5_tensors, axis=0)  # (æ€»å±‚æ•°, lat, lon)
        
        # 5. æŠŠâ€œæ€»å±‚æ•°â€ç»´åº¦å‹åˆ°batchç»´åº¦ï¼ˆæ ¸å¿ƒï¼ï¼‰
        # æ–¹å¼1ï¼šè¿”å›(æ€»å±‚æ•°, lat, lon)ï¼Œåç»­DataLoaderä¼šè‡ªåŠ¨æ‹¼batch â†’ (batch_sizeÃ—æ€»å±‚æ•°, lat, lon)
        # æ–¹å¼2ï¼šæ˜¾å¼æ‰©å±•batchç»´åº¦ â†’ (æ€»å±‚æ•°, 1, lat, lon)ï¼Œåç»­æ‹¼æ¥ä¸º(batch_size, æ€»å±‚æ•°, lat, lon)
        # è¿™é‡Œç”¨æ–¹å¼1ï¼ˆæ›´è´´åˆä½ çš„â€œå‹åˆ°batchç»´åº¦â€éœ€æ±‚ï¼‰
        
        return {
            "gfs": gfs_combined,                # (æ€»å±‚æ•°, lat, lon)
            "era5": era5_combined,              # (æ€»å±‚æ•°, lat, lon)
            "gfs_time": gfs_time.strftime("%Y-%m-%d %H:%M:%S"),
            "era5_time": era5_time.strftime("%Y-%m-%d %H:%M:%S"),
            "gfs_vars": self.gfs_vars,
            "total_layers": self.total_layers
        }